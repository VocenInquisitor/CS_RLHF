# -*- coding: utf-8 -*-
"""RM&CM_Test (1).ipynb

Automatically generated by Colab.

"""

import os
import torch
import numpy as np
from huggingface_hub import login
from transformers import AutoTokenizer
from safe_rlhf.models import AutoModelForScore

import re

# ------------------------------------

# ------------------------------------

# Hugging Face Token
HF_TOKEN = "hf_token"  # <-- Replace with your actual token

# Use your project cache directory
HF_CACHE_DIR = "huggingface_cache"
os.makedirs(HF_CACHE_DIR, exist_ok=True)
os.environ["HF_HOME"] = HF_CACHE_DIR



login(HF_TOKEN)
print("Logged into Hugging Face!")

"""## Reward model"""

MODEL_NAME = "PKU-Alignment/beaver-7b-v3.0-reward"

# Load tokenizer
tokenizer = AutoTokenizer.from_pretrained(
    MODEL_NAME,
    cache_dir=HF_CACHE_DIR,
    use_auth_token=HF_TOKEN
)

# Load reward model
model = AutoModelForScore.from_pretrained(
    MODEL_NAME,
    cache_dir=HF_CACHE_DIR,
    use_auth_token=HF_TOKEN,
    torch_dtype="auto",
    device_map="auto"
)

model.eval()
print("Reward model loaded and ready!")

"""## Txt File JB"""

import math

def get_reward_score(prompt: str, response: str) -> float:
    """
    Compute the average reward score (mean pooling over tokens).
    """
    full_input = f"BEGINNING OF CONVERSATION: USER: {prompt} ASSISTANT:{response}"
    inputs = tokenizer(full_input, return_tensors="pt", truncation=True).to(model.device)

    with torch.no_grad():
        output = model(**inputs)
        reward_score = output.scores.mean().item()

    return reward_score

# def sigmoid(z):
#     return 1 / (1 + np.exp(-z))

def parse_prompt_response_blocks(filepath):
    with open(filepath, "r", encoding="utf-8") as file:
        text = file.read()

    raw_entries = text.split("=" * 80)
    parsed = []

    for idx, entry in enumerate(raw_entries):
        prompt_match = re.search(r'PROMPT:\s*(.*?)\nRESPONSE:', entry, re.DOTALL)
        response_match = re.search(r'RESPONSE:\s*(.*)', entry, re.DOTALL)

        if prompt_match and response_match:
            prompt = prompt_match.group(1).strip()
            response = response_match.group(1).strip()
            parsed.append({
                "id": idx + 1,
                "category": None,
                "prompt": prompt,
                "response": response
            })

    return parsed

filepath = "./Responses.txt"
parsed_data = parse_prompt_response_blocks(filepath)
print(f" Parsed {len(parsed_data)} prompt-response pairs.")

scored_reward_data = []

for entry in parsed_data:
    reward = get_reward_score(entry["prompt"], entry["response"])
    sigmoid_score = 1 / (1 + np.exp(-reward))
    entry["raw_reward_score"] = reward
    entry["sigmoid_reward_score"] = sigmoid_score
    scored_reward_data.append(entry)
    print(f" Scored Prompt {entry['id']} — Sigmoid Reward: {sigmoid_score:.4f}")

output_txt_path = "out.txt"

with open(output_txt_path, "w", encoding="utf-8") as f:
    for entry in scored_reward_data:
        f.write(f"ID: {entry['id']}\n")
        f.write(f"Category: {entry['category']}\n")
        f.write(f"Prompt:\n{entry['prompt']}\n")
        f.write(f"Response:\n{entry['response']}\n")
        f.write(f"Raw Reward Score: {entry['raw_reward_score']:.4f}\n")
        f.write(f"Sigmoid Reward Score: {entry['sigmoid_reward_score']:.4f}\n")
        f.write("=" * 100 + "\n\n")

print(f"\n Scored responses saved to: {output_txt_path}")

"""## Step by Step prompt and Response giving

## Examples from Dataset
"""

from datasets import load_dataset

# Load Safe RLHF dataset (subset with reward model annotations)
dataset = load_dataset("PKU-Alignment/PKU-SafeRLHF", split="train")

print("Dataset loaded!")
print("Number of examples:", len(dataset))

# Loop through first 10 examples
for i in range(10):
    sample = dataset[i]

    prompt = sample["prompt"]
    r0 = sample["response_0"]
    r1 = sample["response_1"]
    preferred_id = sample["better_response_id"]

    # Determine preferred and non-preferred
    preferred = r0 if preferred_id == 0 else r1
    non_preferred = r1 if preferred_id == 0 else r0

    print(f"Example {i+1}")
    print("=" * 80)
    print(f"Prompt:\n{prompt}\n")
    print(f"Preferred Response (response_{preferred_id}):\n{preferred}\n")
    print(f"Non-Preferred Response (response_{1 - preferred_id}):\n{non_preferred}\n")
    print("=" * 80 + "\n")

"""## Cost Model"""

# Hugging Face model name for the cost model
MODEL_NAME = "PKU-Alignment/beaver-7b-v3.0-cost"

# Load tokenizer
tokenizer = AutoTokenizer.from_pretrained(
    MODEL_NAME,
    cache_dir=HF_CACHE_DIR,
    use_auth_token=HF_TOKEN
)

# Load reward model
model = AutoModelForScore.from_pretrained(
    MODEL_NAME,
    cache_dir=HF_CACHE_DIR,
    use_auth_token=HF_TOKEN,
    torch_dtype="auto",  # bfloat16 or float16 depending on your GPU
    device_map="auto"
)

model.eval()
print("Cost model loaded and ready!")

"""## Txt File JB"""

import math

def get_cost_score(prompt: str, response: str):
    """
    Returns both raw and sigmoid-normalized cost scores.
    """
    full_input = f"BEGINNING OF CONVERSATION: USER: {prompt} ASSISTANT:{response}"
    inputs = tokenizer(full_input, return_tensors="pt", truncation=True).to(model.device)

    with torch.no_grad():
        output = model(**inputs)
        raw_score = output.scores.mean().item()
        sigmoid_score = 1 / (1 + math.exp(-raw_score))

    return raw_score, sigmoid_score

def parse_prompt_response_blocks(filepath):
    with open(filepath, "r", encoding="utf-8") as file:
        text = file.read()

    raw_entries = text.split("=" * 80)
    parsed = []

    for idx, entry in enumerate(raw_entries):
        prompt_match = re.search(r'PROMPT:\s*(.*?)\nRESPONSE:', entry, re.DOTALL)
        response_match = re.search(r'RESPONSE:\s*(.*)', entry, re.DOTALL)

        if prompt_match and response_match:
            prompt = prompt_match.group(1).strip()
            response = response_match.group(1).strip()
            parsed.append({
                "id": idx + 1,
                "category": None,
                "prompt": prompt,
                "response": response
            })

    return parsed

# ----------------------------
# Main Execution
# ----------------------------
filepath = "safe-rlhf"  # Ensure this path is correct
parsed_data = parse_prompt_response_blocks(filepath)
print(f"Parsed {len(parsed_data)} prompt-response pairs.")

# Optionally: Score and print results
for entry in parsed_data:
    raw, sigmoid = get_cost_score(entry["prompt"], entry["response"])
    print(f"\n ID {entry['id']} | Raw: {raw:.4f} | Sigmoid: {sigmoid:.4f}")

scored_data = []

for entry in parsed_data:
    raw_score, sigmoid_score = get_cost_score(entry["prompt"], entry["response"])
    entry["raw_cost_score"] = raw_score
    entry["sigmoid_cost_score"] = sigmoid_score
    scored_data.append(entry)
    print(f"Scored Prompt {entry['id']} — Sigmoid Cost: {sigmoid_score:.4f}")

for entry in scored_data[:8]:
    print(f"\n Prompt: {entry['prompt']}\n Response: {entry['response']}")
    print(f" Cost Score → Raw: {entry['raw_cost_score']:.4f} | Sigmoid: {entry['sigmoid_cost_score']:.4f}")

output_txt_path = "costscore.txt"

with open(output_txt_path, "w", encoding="utf-8") as f:
    for entry in scored_data:
        f.write(f"ID: {entry['id']}\n")
        f.write(f"Category: {entry['category']}\n")
        f.write(f"Prompt:\n{entry['prompt']}\n")
        f.write(f"Response:\n{entry['response']}\n")
        f.write(f"Raw Cost Score: {entry['raw_cost_score']:.4f}\n")
        f.write(f"Sigmoid Cost Score: {entry['sigmoid_cost_score']:.4f}\n")
        f.write("=" * 100 + "\n\n")

print(f"\n Scored prompt-responses saved to: {output_txt_path}")
